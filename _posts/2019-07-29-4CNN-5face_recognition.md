---
layout: post
title: "4_CNN_5.face recognition"
subtitle: "4_CNN_5.face recognition"
categories: data
tags: deeplearningai
comments: true
---

# 5.얼굴인식

## 1강

![](https://i.imgur.com/0Eewlm2.png)

- verification(검증): input이미지와, id를 넣으면 →
- 결과로 input이미지가 클레임한 사람인지 아닌지를 출력해줌

- 인식(recognition)문제는 어려움
- 99%로도 100명중에 1명이라는 큰 실수가 나타날 수 있음

## 2.C4W4L02 One Shot Learning

![](https://i.imgur.com/FPbbKRT.png)

- d 함수를 이용하여 이미지 2개를 비교한다
- 이 함수는 다릠의 정도를 나타내는데, 많이 다르다면 10등의 큰 숫자를 반환하고
- 두개의 이미지가 같다면 0에 가까운 값을 반환한다.
- 그래서 위 사진에서는 0.1이 나온게 같다고 표현된다.
- 이거는 데이터 베이스의 신입 사원의 얼굴이 들어와도 값으로 반환하기 때문에 → 오류를 만들지 않음

## C4W4L03 Siamese Network

![](https://i.imgur.com/cLCJT5i.png)

- x1과 x2 사이의 거리에 대해 차이를 놈으로 생각한다
- 이 두 신경망은 서로 같은 파라미터를 갖는다

![](https://i.imgur.com/hjhRC4g.png)

- 두개의 사진이 같다면 두 인코딩의 거리가 짧을 것
- 반대로 다른 사람이라면 놈이 커야할 것
- 신경망의 각 층에 대한 변수들이 서로 다르기 때문에 , 결과적으로 서로 다른 인코딩을 얻게 될 것
- → 그래서 이 조건을 모두 만족시키기 위해서는 → backpropagation을 사용해야함

![](https://i.imgur.com/mxbKJTx.png)

- 같은 사람이면 인코딩이 비슷하고 , 다른 사람이면 인코딩이 많이 다를 것
- 앵커 이미지와, 비교 이미지의 → 그 사이의 거리 계산
- 항상 세 개의 이미지를 동시에 보기 때문에 (앵커이미지, 긍정이미지,부정이미지) (A,P,N)
- d(A,P)  ≤ D(A,N)
- d(A,P)  - D(A,N) ≤ 0
- -알파보다 작아야하는데 (파라미터 값임) 그런데 여기에 알파를 빼기보다는 → 왼쪽에 알파를 더하고 (margin 파라미터)
- (a이미지와 맞는 이미지와의 거리) -  (a이미지와 다른 이미지와의 거리) + 알파(margin) ≤ 0 
→a이미지와 다른 이미지와의 거리가 더 커야함

- 예로 marjin이 0.2라고 하면
- d(a,p) = 0.5 , d(a,n) = 0.51  → 그런데 magin 이 0.2기 때문에 충분하지않음 → 적어도 0.7정도 해야 만족
- 이것이 margin 변수가 하는 일

![](https://i.imgur.com/nxzeLkz.png)

- 만약 천명의 사람에 대한 10000ㄱㅐ의 훈련 세트가 있다면
- 만개의 사진을 사용해서 , 이와 같은 삼중항을 생성하고
- loss값에 대한 gradient descent를 해서 신경망을 훈련시켜야함

- 같은 사람에대한 이미지가 많아야함 그래서 → 1000명의 사람에 대한 10000개의 이미지가 있음
- 만약 한명당 1개의 사진이라면 훈련 시킬 수 업승읎
- 시스템을 훈련 시키고 → 얼굴 인식 시스템의 원샷에 적용할 수 있음 (인식하려는 사람 사진이 1개만 있다면)
- 하지만 최소 몇 사람에 대해서는 여러 개의 이미지가 필요함(a,p,n)

![](https://i.imgur.com/Z5yNoAh.png)

- a, p ,n 을 무작위로 고르면 아래의 제약식을 너무 쉽게 만족해 버림
- (틀린 이미지와의 거리가 쉽게 크게 나타날 수 있음)
- 그러면 너무 쉬워져 gradient descent가 약간 무의미해짐

- 경사 하강법이 d(a,p)와 d(a,n) 의 값들을 서로 멀리 떨어뜨리려는  일을 할 것
- 아래 논문을 참고하면 좋겠다 (faceNet을 개발했음)

### 정리

![](https://i.imgur.com/mkSDfvB.png)

- 위 식을 만족하는 obvious 방법중 하나는 두 거리가 모두 0이 되는 것 (자명)
- 따라서 신경망이 무조건 0을 반환하지 않게 해야함
- 그러기 위해 , 신경망으로 하여금 모든 인코딩이 같지 않다는 것을 알려줘야함 → function을 수정
- margin을 더해주는( 이 역할을 두 거리의 값의 차이가 충분하게 만드는 것)
- max함수는 거리의 차이값이 음수로 나타나는 것을 무시하기 위함
- 램덤으로 뽑으면 → 만약 10개 → a.p는 1개일거고 a.n은 9개 이므로 → 식이 쉽게 만족할 것임

## C4W4L05 Face Verification

![](https://i.imgur.com/BSqu0lv.png)

- 결과 값인 y 예측 값은 어떤 특성들에 적용되는 시그모이드 함수
- k=1 부터 128까지 → 각자의 인코딩 쌍들에 대해 차를 구한 것의 → 절댓값
- f(x^(i)) 는 이미지 x^(i)의 인코딩이라는 뜻
- 이것은 각각의 쌍에 대한 두 인코딩의 차(subtraction)에 절대값을 취한 것
- 이 129개의 숫자들을 특성으로 생각하고 → 로지스틱 회기에 넣고 → 최종 로지스틱 회기는 추가적인 변수인 w와 b가 생긴다
- 초록색 언더라인은 여러 방식으로 계산 할 수 있음 (절댓값 대신 카이제곱, kai^2 si)
- 이 학습의 input은 a pair of image(1개가 아님)
- 그리고 유사도에 따라 0과 1이 된다.

### precompute(배포를 도와주는 트릭)

![](https://i.imgur.com/EDGaODM.png)

- 하나는 얼굴 인식을 기다리는 직원이고 , 하나는 database에 저장된 이미지 일때
- 이 128개의 특성들의 집합 임베딩을 매번 계싼하는 대신 , db에 있는 이미지의 특성 집합 임베딩을 미리 계산해줌(precomputing)
